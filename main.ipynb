{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning  import seed_everything\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from processing_utils import *\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from models import *\n",
    "from model_utils import *\n",
    "\n",
    "seed  = 625\n",
    "seed_everything(seed, workers=True)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/home/yx/肺部并发症预测/Data/model_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_vocab = get_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df.pop('words')\n",
    "text =  df.pop('术前诊断').fillna(\"无\")\n",
    "y = df.pop('肺部并发症').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model, text = get_text_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ids = get_entity_id(words, entity_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat, cont = cat_cont_split(df) \n",
    "df = remove_outliers(df, cont) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"cart\"\n",
    "for num in range(len(cont)):\n",
    "    dtype=\"numerical\"\n",
    "    binning(df, cont, num, method, y, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(embed_cols=df.columns,  \n",
    "                                    for_transformer=True\n",
    "                                )\n",
    "X_tab = tab_preprocessor.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab_train, X_tab_test, y_train_valid, y_test, text_train, text_test, words_ids_train, words_ids_test = time_split(X_tab, text, words_ids, y, 13904)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1024\n",
    "lr = 3e-5\n",
    "epoch = 500\n",
    "agd = 1\n",
    "dropout = 0.6\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True, random_state = 625)\n",
    "results = []\n",
    "n = 0\n",
    "data_loaders = []\n",
    "for train_index, valid_index in kf.split(X_tab_train):\n",
    "    \n",
    "    n += 1\n",
    "\n",
    "    data_loader_train, data_loader_valid, data_loader_valid_test = get_data_loader(\n",
    "            X_tab_train, y_train_valid,train_index, valid_index, b_size     \n",
    "    )\n",
    "    \n",
    "    data_loaders.append(data_loader_valid_test)\n",
    "#     pt_path = \"model_checkpoint/Tabular\"\n",
    "#     pt_name = str(n)+\"_lr=\"+str(lr)+\"_b_size=\"+str(b_size)+\"_agd=\"+str(agd)+\"_dropout=\"+str(dropout)\n",
    "#     logger = TensorBoardLogger(pt_path, name = pt_name)\n",
    "#     model = Tabular(dropout = dropout, lr = lr,column_idx=tab_preprocessor.column_idx ,embed_input=tab_preprocessor.embeddings_input)\n",
    "#     trainer = get_trainer(agd, logger, epoch)\n",
    "#     trainer.fit(model, data_loader_train, data_loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle = True, random_state = 625)\n",
    "# results = []\n",
    "# n = 0\n",
    "# data_loaders = []\n",
    "# for train_index, valid_index in kf.split(X_tab_train):\n",
    "    \n",
    "#     n += 1\n",
    "\n",
    "#     y_train_valid[train_index]\n",
    "#     data_loader_train, data_loader_valid, data_loader_valid_test, data_loader_test = get_Dataloader(\n",
    "#         X_tab_train, text_train, np.array(words_ids_train), y_train_valid, train_index, valid_index, b_size, \n",
    "#         X_tab_test, text_test, words_ids_test, y_test\n",
    "#     )\n",
    "    \n",
    "#     data_loaders.append(data_loader_valid_test)\n",
    "#     pt_path = \"model_checkpoint/test\"\n",
    "#     pt_name = str(n)+\"_lr=\"+str(lr)+\"_b_size=\"+str(b_size)+\"_agd=\"+str(agd)+\"_dropout=\"+str(dropout)\n",
    "#     logger = TensorBoardLogger(pt_path, name = pt_name)\n",
    "#     model = Tabular_text_entity(use_res = True, use_transformer = True,vocab_len = 17372, pre_model = pre_model, dropout = dropout, weight_decay = weight_decay, lr = lr,column_idx=tab_preprocessor.column_idx ,embed_input=tab_preprocessor.embeddings_input)\n",
    "#     trainer = get_trainer(agd, logger, epoch)\n",
    "#     trainer.fit(model, data_loader_train, data_loader_valid)\n",
    "#     torch.cuda.empty_cache()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set_theme()\n",
    "uniform_data = np.random.rand(10, 12)\n",
    "ax = sns.heatmap(model.attention_weights.cpu().detach().numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_pt():\n",
    "    ckpts = []\n",
    "    for i in range(1, 6):\n",
    "        for filepath,dirnames,filenames in os.walk('/home/yx/肺部并发症预测/model_checkpoint/Tabular/'+str(i)+'_lr=3e-05_b_size=1024_agd=1_dropout=0.5/version_0/checkpoints'):\n",
    "            for filename in filenames:\n",
    "                ckpts.append(os.path.join(filepath,filename))\n",
    "    return ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(data_loader_test, model):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    P = []\n",
    "    Y = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader_test:\n",
    "            X = data[0].cuda()\n",
    "            y = data[1].tolist()[0]\n",
    "            Y.append(y)\n",
    "            log_p = model(X)\n",
    "            p = torch.exp(log_p[0][1]).tolist()\n",
    "            P.append(p)\n",
    "    return P, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpts = get_pt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_result(ckpts, data_loaders):\n",
    "    results = []\n",
    "    for pt, data_loader in zip(ckpts, data_loaders):\n",
    "        model = Tabular.load_from_checkpoint(pt, dropout = dropout, lr = lr, column_idx=tab_preprocessor.column_idx, embed_input=tab_preprocessor.embeddings_input)\n",
    "        P, Y = get_predict(data_loader, model)\n",
    "        result = get_metrics(Y, P)\n",
    "        results.append(result)\n",
    "    df_result = get_result(results)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:    0.60455 \t recall:    0.64602 \t f1:    0.62460 \t accuracy:    0.87343 \t aucprc:    0.61837 \t aucroc:    0.87769 \t NPV:    0.92997 \t Specificity:    0.91799 \t \n",
      "precision:    0.49423 \t recall:    0.69930 \t f1:    0.57915 \t accuracy:    0.84286 \t aucprc:    0.57410 \t aucroc:    0.86350 \t NPV:    0.94023 \t Specificity:    0.86947 \t \n",
      "precision:    0.49191 \t recall:    0.68934 \t f1:    0.57413 \t accuracy:    0.83747 \t aucprc:    0.54481 \t aucroc:    0.85090 \t NPV:    0.93623 \t Specificity:    0.86581 \t \n",
      "precision:    0.50275 \t recall:    0.69192 \t f1:    0.58236 \t accuracy:    0.85832 \t aucprc:    0.55073 \t aucroc:    0.87552 \t NPV:    0.94502 \t Specificity:    0.88637 \t \n",
      "precision:    0.59389 \t recall:    0.64916 \t f1:    0.62030 \t accuracy:    0.87986 \t aucprc:    0.60112 \t aucroc:    0.87875 \t NPV:    0.93629 \t Specificity:    0.92122 \t \n"
     ]
    }
   ],
   "source": [
    "# ckpts = get_pt('/home/yx/3090/project/P_prediction/肺部并发症预测/model_checkpoint/')\n",
    "df_result = get_model_result(ckpts, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>aucprc</th>\n",
       "      <th>aucroc</th>\n",
       "      <th>NPV</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>均值</th>\n",
       "      <td>0.537467</td>\n",
       "      <td>0.675149</td>\n",
       "      <td>0.596106</td>\n",
       "      <td>0.858388</td>\n",
       "      <td>0.577827</td>\n",
       "      <td>0.869270</td>\n",
       "      <td>0.937547</td>\n",
       "      <td>0.892174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>置信区间-左</th>\n",
       "      <td>0.487818</td>\n",
       "      <td>0.652845</td>\n",
       "      <td>0.574831</td>\n",
       "      <td>0.842191</td>\n",
       "      <td>0.550024</td>\n",
       "      <td>0.858801</td>\n",
       "      <td>0.932672</td>\n",
       "      <td>0.869173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>置信区间-右</th>\n",
       "      <td>0.587117</td>\n",
       "      <td>0.697453</td>\n",
       "      <td>0.617382</td>\n",
       "      <td>0.874584</td>\n",
       "      <td>0.605630</td>\n",
       "      <td>0.879739</td>\n",
       "      <td>0.942421</td>\n",
       "      <td>0.915174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision    recall        f1  accuracy    aucprc    aucroc       NPV  \\\n",
       "均值       0.537467  0.675149  0.596106  0.858388  0.577827  0.869270  0.937547   \n",
       "置信区间-左   0.487818  0.652845  0.574831  0.842191  0.550024  0.858801  0.932672   \n",
       "置信区间-右   0.587117  0.697453  0.617382  0.874584  0.605630  0.879739  0.942421   \n",
       "\n",
       "        Specificity  \n",
       "均值         0.892174  \n",
       "置信区间-左     0.869173  \n",
       "置信区间-右     0.915174  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['model'] = 'deep-learning'\n",
    "df_result['text'] = '无'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ppc_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ebecbfc39e46400fc8caa0428915fda84dbccf5b6b12ee1d80137830984842c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
